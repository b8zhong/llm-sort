# LLM Sort Evaluation

This project evaluates Large Language Models' (LLMs) ability to perform sorting tasks using the reasoning-gym framework.

## Project Structure

- `src/`: Source code for the evaluation framework
- `evals/`: Evaluation scripts and results
  - `benchmarks/`: Benchmark datasets and test cases
  
## Setup

1. Create a virtual environment (recommended):
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

## Usage

[To be added as the project develops] 